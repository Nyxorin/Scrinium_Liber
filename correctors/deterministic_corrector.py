#!/usr/bin/env python3
"""
Correcteur d√©terministe - Module 1 du pipeline.
Principe Odoo: H√©ritage de BaseCorrector + sp√©cialisation.

Responsabilit√©s:
- Appliquer les 164+ substitutions de la base de donn√©es OCR
- Corrections de mise en page (espaces, c√©sures, ponctuation)
- Normalisation des guillemets fran√ßais
- Corrections des contractions (d7un ‚Üí d'un, n7avait ‚Üí n'avait)

Avantages:
- ‚úÖ Rapide (< 0.1 sec pour tout le livre)
- ‚úÖ Fiable √† 100% (r√®gles d√©terministes)
- ‚úÖ Corrige ~80% des erreurs simples

Limitations:
- ‚ùå Ne comprend pas le contexte
- ‚ùå Peut cr√©er de nouveaux non-mots (valid√© par module suivant)
"""

import re
import json
from pathlib import Path
from typing import List, Tuple
from .base_corrector import BaseCorrector, CorrectionSuggestion


class DeterministicCorrector(BaseCorrector):
    """
    Correcteur d√©terministe bas√© sur des r√®gles fixes.
    Confiance: 100%
    """

    def __init__(self, rules_path: str = None):
        super().__init__()
        if rules_path is None:
            # Chemin par d√©faut relatif √† ce fichier
            rules_path = Path(__file__).parent.parent / "core" / "corrections.json"
        
        self.rules_path = Path(rules_path)
        self.rules = self._load_rules()
        self.simple_corrections = self._build_simple_corrections()
        self.regex_corrections = self._build_regex_corrections()
        # [Phase 33] Append Logic Forge Rules
        self.regex_corrections.extend(self._load_dynamic_rules())
        
        # [V4 SANDWICH STRATEGY] - The Cleaner
        # Hardcoded high-confidence rules from Historical Audit
        self.apostrophe_replacements = {
            "‚Äô": "'", "¬¥": "'", "`": "'", "‚Äò": "'", "‚Äú": "\"", "‚Äù": "\"", 
            "¬´": "¬´ ", "¬ª": " ¬ª" # Normalisation espaces guillemets
        }
        self.ligature_replacements = {
            "≈í": "Oe", "≈ì": "oe", "√Ü": "Ae", "√¶": "ae", 
            "Ô¨Å": "fi", "Ô¨Ç": "fl", "Ô¨Ä": "ff", "Ô¨É": "ffi", "Ô¨Ñ": "ffl"
        }
        # [V7.2 Specific Visual Patches]
        self.visual_patches = {
            "chauf≈í": "chauff",
            "≈íuf": "Oeuf", # Keep OE generally, but maybe check specific words?
        }

    def _load_rules(self) -> dict:
        """Charge les r√®gles depuis le fichier JSON."""
        if not self.rules_path.exists():
            print(f"‚ö†Ô∏è Fichier de r√®gles non trouv√©: {self.rules_path}")
            return {"simple_replacements": [], "regex_replacements": [], "contraction_prefixes": [], "contraction_suspect_chars": []}
        
        try:
            with open(self.rules_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement des r√®gles: {e}")
            return {"simple_replacements": [], "regex_replacements": [], "contraction_prefixes": [], "contraction_suspect_chars": []}

    def get_name(self) -> str:
        return "Correcteur D√©terministe"

    def get_confidence(self) -> float:
        return 1.0  # 100% confiance - r√®gles d√©terministes

    def _build_simple_corrections(self) -> List[Tuple[str, str]]:
        """
        Construit la liste des corrections simples depuis le JSON.
        """
        return [(r["old"], r["new"]) for r in self.rules.get("simple_replacements", [])]

    def _build_regex_corrections(self) -> List[Tuple[str, str, str]]:
        """
        Construit la liste des corrections regex depuis le JSON.
        """
        corrections = []
        
        # Charger les regex directes
        for r in self.rules.get("regex_replacements", []):
            corrections.append((r["pattern"], r["replacement"], r["description"]))
        
        # G√©n√©rer dynamiquement les contractions si les pr√©fixes sont fournis
        prefixes = self.rules.get("contraction_prefixes", [])
        suspect_chars = self.rules.get("contraction_suspect_chars", [])
        
        if prefixes and suspect_chars:
            suspect_pattern = "[" + "".join(re.escape(c) for c in suspect_chars) + "]"
            for prefix in prefixes:
                corrections.append((
                    rf"\b{prefix}{suspect_pattern}",
                    f"{prefix}'",
                    f"Contraction {prefix}X ‚Üí {prefix}'"
                ))
        
        return corrections

        return corrections

    def _load_dynamic_rules(self) -> List[Tuple[str, str, str]]:
        """
        [Phase 32/33] Loads rules generated by the Logic Forge.
        Path: data/logic_forge_rules.jsonl
        """
        dynamic_rules = []
        path = Path("data/logic_forge_rules.jsonl")
        if not path.exists():
            return []
            
        try:
            with open(path, 'r', encoding='utf-8') as f:
                for line in f:
                    if not line.strip(): continue
                    rule = json.loads(line)
                    # Expected format: {"pattern": "...", "replacement": "..."}
                    if "pattern" in rule and "replacement" in rule:
                        desc = rule.get("example_fix", "Logic Forge Rule")
                        dynamic_rules.append((rule["pattern"], rule["replacement"], f"Forge: {desc}"))
            print(f"üî• Logic Forge: Loaded {len(dynamic_rules)} rules.")
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading Logic Forge rules: {e}")
            
        return dynamic_rules

    def correct(self, text: str) -> str:
        """
        Applique toutes les corrections d√©terministes.

        Args:
            text: Texte √† corriger

        Returns:
            Texte corrig√©
        """
        original_text = text
        current_text = text

        # [V4 SANDWICH STRATEGY] - The Cleaner
        
        # 1. Structural Cleaning (Category 4: Page Numbers) - Confidence 100%
        # Remove lines that are just numbers or "Page X"
        # Since this method processes a string (possibly multiline), we process line by line.
        lines = []
        for line in current_text.splitlines():
            stripped = line.strip()
            # Regex: Isolated digits (ex: "123") or "Page 123", or "- 123 -" or "[123]"
            if re.match(r'^\s*(?:-\s*)?\[?\d+\]?(?:\s*-)?\s*$', stripped) or re.match(r'^Page \d+$', stripped, re.IGNORECASE):
                 continue # Delete line (page number)
            
            # [V7.1 Noise Scrubber] Remove lines with only special chars (no letters/digits)
            # Ex: | * _ ‚Äî . ,
            if re.match(r'^[\W_]+$', stripped):
                continue

            lines.append(line)
        current_text = "\n".join(lines)

        # 2. Apostrophes & Quotes (Category 1) - Confidence 100%
        for char, repl in self.apostrophe_replacements.items():
            if char in current_text:
                current_text = current_text.replace(char, repl)

        # 3. Ligatures (Category 5) - Confidence 100%
        # 3. Ligatures (Category 5) - Confidence 100%
        # Apply specific visual patches first (before breaking ligatures)
        for bad, good in self.visual_patches.items():
            if bad in current_text:
                current_text = current_text.replace(bad, good)

        for char, repl in self.ligature_replacements.items():
            if char in current_text:
                current_text = current_text.replace(char, repl)

        # 4. Special Chars (Category 3) - Confidence 95%
        # @ is often an OCR error for ' inside words like l@
        current_text = re.sub(r'(?<=[a-zA-Z√†-√∂√∏-√ø])@(?=[a-zA-Z√†-√∂√∏-√ø])', "'", current_text)
        # Others are noise
        current_text = re.sub(r'(?<=[a-zA-Z√†-√∂√∏-√ø])[*#$](?=[a-zA-Z√†-√∂√∏-√ø])', '', current_text)

        # 5. Corrections Simples
        for old, new in self.simple_corrections:
            before = current_text
            current_text = current_text.replace(old, new)
            if current_text != before:
                self.corrections_count += 1

        # √âtape 5: Corrections regex
        for pattern, replacement, description in self.regex_corrections:
            before = current_text
            current_text = re.sub(pattern, replacement, current_text)
            if current_text != before:
                self.corrections_count += 1

        return current_text

    def get_suggestions(self, text: str, max_suggestions: int = 5) -> List[CorrectionSuggestion]:
        """
        G√©n√®re des suggestions de correction.

        Pour le correcteur d√©terministe, on retourne une seule suggestion:
        le texte corrig√© avec 100% de confiance.
        """
        corrected = self.correct(text)

        if corrected != text:
            return [CorrectionSuggestion(
                original=text,
                corrected=corrected,
                confidence=1.0,
                reason="Corrections d√©terministes appliqu√©es",
                alternatives=[]
            )]

        return []


if __name__ == "__main__":
    # Test du correcteur d√©terministe
    print("=" * 80)
    print("üß™ TEST DU CORRECTEUR D√âTERMINISTE")
    print("=" * 80)
    print()

    corrector = DeterministicCorrector()

    # Tests avec diff√©rents types d'erreurs
    test_cases = [
        "d7un homme",
        "n7avait pas",
        "l@Afrique",
        "mi] icien",
        "appi endre",
        "1es maisons",
        "C7√©tait un m0ment",
        "Le texte.Sans espace",
        "mil icien de profession",
    ]

    print("Tests de correction:")
    print("-" * 80)

    for test in test_cases:
        corrected = corrector.correct(test)
        if corrected != test:
            print(f"‚úÖ '{test}' ‚Üí '{corrected}'")
        else:
            print(f"   '{test}' (inchang√©)")

    print()
    corrector.print_stats()
